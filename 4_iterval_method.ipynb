{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interval method for weather predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_rmse(target, preds):\n",
    "    rmse = mean_squared_error(target, preds, squared=False)\n",
    "    avg = np.full(len(preds), preds.mean())\n",
    "    const_rmse = mean_squared_error(target, avg, squared=False)\n",
    "    return rmse / const_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "high = pd.read_csv('predicted_weather/prophet_high.csv')\n",
    "low = pd.read_csv('predicted_weather/prophet_low.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1f/xyznj37x1n337kxt0v5533rw0000gn/T/ipykernel_13481/844755778.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  low['VAP'][low['VAP'] < 0] = 0.06\n",
      "/var/folders/1f/xyznj37x1n337kxt0v5533rw0000gn/T/ipykernel_13481/844755778.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  low['RAIN'][low['RAIN'] < 0] = 0\n"
     ]
    }
   ],
   "source": [
    "low['VAP'][low['VAP'] < 0] = 0.06\n",
    "low['RAIN'][low['RAIN'] < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1f/xyznj37x1n337kxt0v5533rw0000gn/T/ipykernel_13481/2604046005.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  high['VAP'][high['VAP'] < 0] = 0.06\n",
      "/var/folders/1f/xyznj37x1n337kxt0v5533rw0000gn/T/ipykernel_13481/2604046005.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  high['RAIN'][high['RAIN'] < 0] = 0\n"
     ]
    }
   ],
   "source": [
    "high['VAP'][high['VAP'] < 0] = 0.06\n",
    "high['RAIN'][high['RAIN'] < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "low.to_csv('predicted_weather/prophet_low.csv', index=False)\n",
    "high.to_csv('predicted_weather/prophet_high.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = low.merge(high, on=['DAY', 'SNOWDEPTH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dateset(df, name, n):\n",
    "    df[f'Width_{name}'] = df[f'{name}_y'] - df[f'{name}_x'] \n",
    "    df[f'Delta_{name}'] = df[f'Width_{name}'] / n\n",
    "    temp = df[[f'Delta_{name}', f'{name}_x']].copy()\n",
    "    for i in range(1, n+1):\n",
    "        temp[f'{name}_{i}'] = temp[f'{name}_x'] + i * temp[f'Delta_{name}']\n",
    "    temp.rename({f'{name}_x': f'{name}_0'}, axis=1, inplace=True)\n",
    "    return temp.drop([f'Delta_{name}'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "irrad = get_dateset(pivot, 'IRRAD', n)\n",
    "tmin = get_dateset(pivot, 'TMIN', n)\n",
    "tmax = get_dateset(pivot, 'TMAX', n)\n",
    "vap = get_dateset(pivot, 'VAP', n)\n",
    "wind = get_dateset(pivot, 'WIND', n)\n",
    "rain = get_dateset(pivot, 'RAIN', n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "irrad.to_csv('predicted_weather/interval_data/irrad.csv', index=False)\n",
    "tmin.to_csv('predicted_weather/interval_data/tmin.csv', index=False)\n",
    "tmax.to_csv('predicted_weather/interval_data/tmax.csv', index=False)\n",
    "vap.to_csv('predicted_weather/interval_data/vap.csv', index=False)\n",
    "wind.to_csv('predicted_weather/interval_data/wind.csv', index=False)\n",
    "rain.to_csv('predicted_weather/interval_data/rain.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_columns(x:int):\n",
    "    all_files = []\n",
    "    for x1 in range(n+1):\n",
    "        for x2 in range(n+1):\n",
    "            for x3 in range(n+1):\n",
    "                for x4 in range(n+1):\n",
    "                    for x5 in range(n+1):\n",
    "                        for x6 in range(n+1):\n",
    "                            tmp = low[['DAY', 'SNOWDEPTH']].copy()\n",
    "                            tmp['IRRAD'] = irrad[f'IRRAD_{x1}']\n",
    "                            tmp['TMIN'] = tmin[f'TMIN_{x2}']\n",
    "                            tmp['TMAX'] = tmax[f'TMAX_{x3}']\n",
    "                            tmp['VAP'] = vap[f'VAP_{x4}']\n",
    "                            tmp['WIND'] = wind[f'WIND_{x5}']\n",
    "                            tmp['RAIN'] = rain[f'RAIN_{x6}']\n",
    "                            fname = f'predicted_weather/interval_data/{x1}_{x2}_{x3}_{x4}_{x5}_{x6}.csv'\n",
    "                            fname = f'predicted_weather/interval_data/{x}_{x2}_{x3}_{x4}_{x5}_{x6}.csv'\n",
    "                            all_files.append(fname)\n",
    "        break\n",
    "                            # tmp.to_csv(fname, index=False)\n",
    "    return all_files\n",
    "                            # Думаю хорошо бы удалять CSV с погодой после запуска - os.remove(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_columns(n:int, x1:int, x2:int):\n",
    "    all_files = []\n",
    "    for x3 in range(n+1):\n",
    "        for x4 in range(n+1):\n",
    "            for x5 in range(n+1):\n",
    "                for x6 in range(n+1):\n",
    "                    # tmp = low[['DAY', 'SNOWDEPTH']].copy()\n",
    "                    # tmp['IRRAD'] = irrad[f'IRRAD_{x1}']\n",
    "                    # tmp['TMIN'] = tmin[f'TMIN_{x2}']\n",
    "                    # tmp['TMAX'] = tmax[f'TMAX_{x3}']\n",
    "                    # tmp['VAP'] = vap[f'VAP_{x4}']\n",
    "                    # tmp['WIND'] = wind[f'WIND_{x5}']\n",
    "                    # tmp['RAIN'] = rain[f'RAIN_{x6}']\n",
    "                    # fname = f'predicted_weather/interval_data/{x1}_{x2}_{x3}_{x4}_{x5}_{x6}.csv'\n",
    "                    fname = f'predicted_weather/interval_data/{x1}_{x2}_{x3}_{x4}_{x5}_{x6}.csv'\n",
    "                    all_files.append(fname)\n",
    "        \n",
    "\n",
    "                            # tmp.to_csv(fname, index=False)\n",
    "    return all_files\n",
    "                            # Думаю хорошо бы удалять CSV с погодой после запуска - os.remove(fname)\n",
    "all_files = product_columns(n=8, x1=0, x2=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WOFOST & Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, sys, math, yaml\n",
    "import datetime as dt\n",
    "from dateutil.parser import parse\n",
    "import pandas as pd\n",
    "#Plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime as dt\n",
    "import json\n",
    "\n",
    "# from pcse.fileinput import YAMLAgroManagementReader\n",
    "from pcse.util import WOFOST71SiteDataProvider, WOFOST72SiteDataProvider\n",
    "# from pcse.fileinput import PCSEFileReader\n",
    "\n",
    "import pcse\n",
    "\n",
    "from pcse.models import Wofost72_PP, Wofost72_WLP_FD\n",
    "from pcse.fileinput import YAMLCropDataProvider\n",
    "\n",
    "from pcse.util import WOFOST72SiteDataProvider, DummySoilDataProvider\n",
    "from pcse.base import ParameterProvider\n",
    "from pcse.engine import Engine\n",
    "from pcse.fileinput.csvweatherdataprovider import CSVWeatherDataProvider\n",
    "\n",
    "\n",
    "def prepareWeather(in_fname: str):\n",
    "    \"\"\"\n",
    "    Read weather file, after convert to WOFOST CSV format and \n",
    "    read into memory to PCSE weather Class\n",
    "    \n",
    "    in: in_fname (str) - path to csv file with weather time-series\n",
    "    \"\"\"\n",
    "    # read weather time-series\n",
    "    weather_df = pd.read_csv(in_fname)\n",
    "    # future name\n",
    "\n",
    "    path_to_save_csv_file = os.path.splitext(in_fname)[0]+'_WOFOST.csv'\n",
    "    # path_to_save_csv_file = './wofost_weather.csv'\n",
    "    # pattern for WOFOST format\n",
    "    text = open('./pattern.csv', \"r\")\n",
    "    dictReplace = {\n",
    "        \"1111\": \"37.0\",\n",
    "        \"2222\": \"51.5\",\n",
    "        \"3333\": \"210.05\", # m\n",
    "        \"4444\": \"0.172729\",\n",
    "        \"5555\": \"0.565318\",\n",
    "    }\n",
    "    for key, value in dictReplace.items():\n",
    "        text = \"\".join([i for i in text]).replace(key, str(value))\n",
    "    x = open(path_to_save_csv_file, \"w\")\n",
    "    x.writelines(text)\n",
    "    x.close()\n",
    "    weather_df.to_csv(\n",
    "        path_to_save_csv_file, mode=\"a\", header=False, index=False, na_rep='NaN'\n",
    "    )\n",
    "    weather = CSVWeatherDataProvider(path_to_save_csv_file)\n",
    "    return weather\n",
    "\n",
    "\n",
    "def run_wofost(weather, \n",
    "              sowing_date:str,\n",
    "              harvesting_date:str,\n",
    "              crop_end_type: str = 'maturity',\n",
    "              crop_name:str = 'sugarbeet',\n",
    "              crop_variety:str = 'Sugarbeet_603', \n",
    "              models: list = ['FLD', 'PP'])-> dict:\n",
    "\n",
    "    \"\"\"\n",
    "        Prepare parameters: meteo, agrotechnology and run WOFOST simulation in PP and FLD modes.   \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        crop_name: str\n",
    "            Crop name fow WOFOST model\n",
    "        crop_variety: str\n",
    "            Crop variety fow WOFOST crop \n",
    "        sowing_date: str\n",
    "            Date of crop sowing, ex. %Y-%m-%d\n",
    "        harvest_date: str \n",
    "        - optional\n",
    "            Date of crop harvest, ex. %Y-%m-%d\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        results: dict \n",
    "            dict with PCSE objects: cropd, wdp\n",
    "            if run_similation: True \n",
    "                return computed default yield\n",
    "        To-Do\n",
    "        -----\n",
    "\n",
    "\n",
    "        Example\n",
    "        -------\n",
    "\n",
    "    \"\"\"\n",
    "    cropd = YAMLCropDataProvider(repository=\"https://raw.githubusercontent.com/ajwdewit/WOFOST_crop_parameters/master/\")\n",
    "    # Some site parameters\n",
    "    sited = WOFOST71SiteDataProvider(WAV=50, SMLIM=0.7)\n",
    "\n",
    "    soild = DummySoilDataProvider() # Used real soil parameters from kshen \n",
    "\n",
    "    soild['SMW'] = 0.15\n",
    "    soild['SMFCF'] = 0.3\n",
    "    soild['SM0'] = 0.566 \n",
    "\n",
    "    _campaign_start_date_dt = parse(sowing_date) -  dt.timedelta(days=5)\n",
    "    campaign_start_date = dt.datetime.strftime(_campaign_start_date_dt, format='%Y-%m-%d')\n",
    "\n",
    "    max_duration = 300\n",
    "\n",
    "    # Here we define the agromanagement for crop\n",
    "    agro_yaml = f\"\"\"\n",
    "    - {campaign_start_date}:\n",
    "        CropCalendar:\n",
    "            crop_name: {crop_name}\n",
    "            variety_name: {crop_variety}\n",
    "            crop_start_date: {sowing_date}\n",
    "            crop_start_type: emergence\n",
    "            crop_end_date: {harvesting_date}\n",
    "            crop_end_type: {crop_end_type}\n",
    "            max_duration: {max_duration}\n",
    "        TimedEvents: null\n",
    "        StateEvents: null\n",
    "    \"\"\"\n",
    "    agro = yaml.safe_load(agro_yaml)\n",
    "\n",
    "    firstkey = list(agro[0])[0]\n",
    "    cropcalendar = agro[0][firstkey]['CropCalendar'] \n",
    "\n",
    "    cropd.set_active_crop(cropcalendar['crop_name'], cropcalendar['variety_name'])\n",
    "\n",
    "    params = ParameterProvider(cropdata=cropd, sitedata=sited, soildata=soild)\n",
    "\n",
    "    defualtCropYield={}\n",
    "    \n",
    "    modelDict = {'FLD':Wofost72_WLP_FD, \n",
    "                'PP': Wofost72_PP}\n",
    "    for model_type in ['FLD']:\n",
    "        params = ParameterProvider(cropdata=cropd, sitedata=sited, soildata=soild)\n",
    "        model_runner = modelDict[model_type](params, weather, agro)\n",
    "        model_runner.run_till_terminate()\n",
    "        r = model_runner.get_output()\n",
    "        defualtCropYield[model_type]=r\n",
    "        del model_runner\n",
    "    del weather\n",
    "    return defualtCropYield\n",
    "\n",
    "\n",
    "def getCropCalendar(crop:str,\n",
    "                    year:str)->dict:\n",
    "\n",
    "    dictAgro = {'barley': {'plant_day': '2021-04-30', 'harvest_day': '2021-09-06'},\n",
    "    'soybean': {'plant_day': '2021-04-15', 'harvest_day': '2021-08-16'},\n",
    "    'wheat': {'plant_day': '2021-05-18', 'harvest_day': '2021-09-01'},\n",
    "    'sugarbeet': {'plant_day': '2021-04-28', 'harvest_day': '2021-10-05'}}\n",
    "\n",
    "    return {'plant_day': dictAgro[crop]['plant_day'].replace('2021', year),\n",
    "            'harvest_day': dictAgro[crop]['harvest_day'].replace('2021', year)}\n",
    "\n",
    "\n",
    "\n",
    "cropsDict = {'barley':'Spring_barley_301', \n",
    "            'soybean':'Soybean_901',\n",
    "            'sunflower':'Sunflower_1101',\n",
    "            'maize':'Grain_maize_201', \n",
    "            'sugarbeet':'Sugarbeet_603'}\n",
    "            \n",
    "\n",
    "cols = ['crop', 'year', 'WOFOST_FLD']\n",
    "crops = ['barley', 'soybean', 'sugarbeet']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeCrop(general_df: pd.DataFrame, weather_fname: str, uuid_code:str):\n",
    "    cols = ['crop', 'year', 'WOFOST_FLD', 'weather_uuid']\n",
    "    weather = prepareWeather(weather_fname)\n",
    "    df = pd.DataFrame(columns=cols)\n",
    "\n",
    "    for crop in crops:\n",
    "        for year in range(2015,2020):\n",
    "            cropCal = getCropCalendar(crop, str(year))\n",
    "            crop_model_yield = run_wofost(weather = weather,\n",
    "                    sowing_date = cropCal['plant_day'],\n",
    "                    harvesting_date = cropCal['harvest_day'],\n",
    "                    crop_name = crop,\n",
    "                    crop_variety = cropsDict[crop],\n",
    "                    crop_end_type='harvest')\n",
    "            water_limited_df = pd.DataFrame(crop_model_yield['FLD'])\n",
    "            water_limited_yield = crop_model_yield['FLD'][-1]['TWSO']\n",
    "            df.loc[len(df)] = [crop, year, water_limited_yield, uuid_code]\n",
    "    return pd.concat([general_df,df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import ge\n",
    "\n",
    "\n",
    "def product_columns(n: int, x1: int, x2: int):\n",
    "    cols = [\"crop\", \"year\", \"WOFOST_FLD\", \"weather_uuid\"]\n",
    "    general_df = pd.DataFrame(columns=cols)\n",
    "\n",
    "    all_files = []\n",
    "    for x3 in range(n + 1):\n",
    "        for x4 in range(n + 1):\n",
    "            for x5 in range(n + 1):\n",
    "                for x6 in range(n + 1):\n",
    "                    tmp = low[[\"DAY\", \"SNOWDEPTH\"]].copy()\n",
    "                    tmp[\"IRRAD\"] = irrad[f\"IRRAD_{x1}\"]\n",
    "                    tmp[\"TMIN\"] = tmin[f\"TMIN_{x2}\"]\n",
    "                    tmp[\"TMAX\"] = tmax[f\"TMAX_{x3}\"]\n",
    "                    tmp[\"VAP\"] = vap[f\"VAP_{x4}\"]\n",
    "                    tmp[\"WIND\"] = wind[f\"WIND_{x5}\"]\n",
    "                    tmp[\"RAIN\"] = rain[f\"RAIN_{x6}\"]\n",
    "                    fname = f\"predicted_weather/interval_data/{x1}_{x2}_{x3}_{x4}_{x5}_{x6}.csv\"\n",
    "\n",
    "                    weather_uuid = f\"{x1}_{x2}_{x3}_{x4}_{x5}_{x6}\"\n",
    "                    tmp.to_csv(fname, index=False)\n",
    "                    all_files.append(fname)\n",
    "                    general_df = computeCrop(\n",
    "                        general_df=general_df,\n",
    "                        weather_fname=fname,\n",
    "                        uuid_code=weather_uuid,\n",
    "                    )\n",
    "                    os.remove(fname)\n",
    "                    # save data\n",
    "\n",
    "                    if len(all_files)%1000==0:\n",
    "                        dirname = './results/'\n",
    "                        general_fname = os.path.join(dirname, f\"WOFOST_{x1}_{x2}.csv\")\n",
    "                        general_df.to_csv(general_fname, index=False)\n",
    "                    # tmp.to_csv(fname, index=False)\n",
    "    return all_files\n",
    "    # Думаю хорошо бы удалять CSV с погодой после запуска - os.remove(fname)\n",
    "\n",
    "\n",
    "all_files = product_columns(n=8, x1=0, x2=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, yaml\n",
    "import datetime as dt\n",
    "from dateutil.parser import parse\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "# Plotting\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "import pcse\n",
    "from pcse.util import WOFOST71SiteDataProvider, WOFOST72SiteDataProvider\n",
    "from pcse.models import Wofost72_PP, Wofost72_WLP_FD\n",
    "from pcse.fileinput import YAMLCropDataProvider\n",
    "\n",
    "from pcse.util import WOFOST72SiteDataProvider, DummySoilDataProvider\n",
    "from pcse.base import ParameterProvider\n",
    "from pcse.engine import Engine\n",
    "from pcse.fileinput.csvweatherdataprovider import CSVWeatherDataProvider\n",
    "\n",
    "\n",
    "def prepareWeather(in_fname: str):\n",
    "    \"\"\"\n",
    "    Read weather file, after convert to WOFOST CSV format and\n",
    "    read into memory to PCSE weather Class\n",
    "\n",
    "    in: in_fname (str) - path to csv file with weather time-series\n",
    "    \"\"\"\n",
    "    # read weather time-series\n",
    "    weather_df = pd.read_csv(in_fname)\n",
    "    # future name\n",
    "\n",
    "    path_to_save_csv_file = os.path.splitext(in_fname)[0] + \"_WOFOST.csv\"\n",
    "    # path_to_save_csv_file = './wofost_weather.csv'\n",
    "    # pattern for WOFOST format\n",
    "    text = open(\"./pattern.csv\", \"r\")\n",
    "    dictReplace = {\n",
    "        \"1111\": \"37.0\",\n",
    "        \"2222\": \"51.5\",\n",
    "        \"3333\": \"210.05\",  # m\n",
    "        \"4444\": \"0.172729\",\n",
    "        \"5555\": \"0.565318\",\n",
    "    }\n",
    "    for key, value in dictReplace.items():\n",
    "        text = \"\".join([i for i in text]).replace(key, str(value))\n",
    "    x = open(path_to_save_csv_file, \"w\")\n",
    "    x.writelines(text)\n",
    "    x.close()\n",
    "    weather_df.to_csv(\n",
    "        path_to_save_csv_file, mode=\"a\", header=False, index=False, na_rep=\"NaN\"\n",
    "    )\n",
    "    weather = CSVWeatherDataProvider(path_to_save_csv_file)\n",
    "    os.remove(path_to_save_csv_file)\n",
    "    return weather\n",
    "\n",
    "\n",
    "def run_wofost(\n",
    "    weather,\n",
    "    sowing_date: str,\n",
    "    harvesting_date: str,\n",
    "    crop_end_type: str = \"maturity\",\n",
    "    crop_name: str = \"sugarbeet\",\n",
    "    crop_variety: str = \"Sugarbeet_603\",\n",
    "    models: list = [\"FLD\", \"PP\"],\n",
    ") -> dict:\n",
    "\n",
    "    \"\"\"\n",
    "    Prepare parameters: meteo, agrotechnology and run WOFOST simulation in PP and FLD modes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    crop_name: str\n",
    "        Crop name fow WOFOST model\n",
    "    crop_variety: str\n",
    "        Crop variety fow WOFOST crop\n",
    "    sowing_date: str\n",
    "        Date of crop sowing, ex. %Y-%m-%d\n",
    "    harvest_date: str\n",
    "    - optional\n",
    "        Date of crop harvest, ex. %Y-%m-%d\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    results: dict\n",
    "        dict with PCSE objects: cropd, wdp\n",
    "        if run_similation: True\n",
    "            return computed default yield\n",
    "    To-Do\n",
    "    -----\n",
    "\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "    cropd = YAMLCropDataProvider(\n",
    "        repository=\"https://raw.githubusercontent.com/ajwdewit/WOFOST_crop_parameters/master/\"\n",
    "    )\n",
    "    # Some site parameters\n",
    "    sited = WOFOST71SiteDataProvider(WAV=50, SMLIM=0.7)\n",
    "\n",
    "    soild = DummySoilDataProvider()  # Used real soil parameters from kshen\n",
    "\n",
    "    soild[\"SMW\"] = 0.15\n",
    "    soild[\"SMFCF\"] = 0.3\n",
    "    soild[\"SM0\"] = 0.566\n",
    "\n",
    "    _campaign_start_date_dt = parse(sowing_date) - dt.timedelta(days=5)\n",
    "    campaign_start_date = dt.datetime.strftime(\n",
    "        _campaign_start_date_dt, format=\"%Y-%m-%d\"\n",
    "    )\n",
    "\n",
    "    max_duration = 300\n",
    "\n",
    "    # Here we define the agromanagement for crop\n",
    "    agro_yaml = f\"\"\"\n",
    "    - {campaign_start_date}:\n",
    "        CropCalendar:\n",
    "            crop_name: {crop_name}\n",
    "            variety_name: {crop_variety}\n",
    "            crop_start_date: {sowing_date}\n",
    "            crop_start_type: emergence\n",
    "            crop_end_date: {harvesting_date}\n",
    "            crop_end_type: {crop_end_type}\n",
    "            max_duration: {max_duration}\n",
    "        TimedEvents: null\n",
    "        StateEvents: null\n",
    "    \"\"\"\n",
    "    agro = yaml.safe_load(agro_yaml)\n",
    "\n",
    "    firstkey = list(agro[0])[0]\n",
    "    cropcalendar = agro[0][firstkey][\"CropCalendar\"]\n",
    "\n",
    "    cropd.set_active_crop(cropcalendar[\"crop_name\"], cropcalendar[\"variety_name\"])\n",
    "\n",
    "    params = ParameterProvider(cropdata=cropd, sitedata=sited, soildata=soild)\n",
    "\n",
    "    defualtCropYield = {}\n",
    "\n",
    "    modelDict = {\"FLD\": Wofost72_WLP_FD, \"PP\": Wofost72_PP}\n",
    "    for model_type in [\"FLD\"]:\n",
    "        params = ParameterProvider(cropdata=cropd, sitedata=sited, soildata=soild)\n",
    "        model_runner = modelDict[model_type](params, weather, agro)\n",
    "        model_runner.run_till_terminate()\n",
    "        r = model_runner.get_output()\n",
    "        defualtCropYield[model_type] = r\n",
    "        del model_runner\n",
    "    del weather\n",
    "    return defualtCropYield\n",
    "\n",
    "\n",
    "def getCropCalendar(crop: str, year: str) -> dict:\n",
    "\n",
    "    dictAgro = {\n",
    "        \"barley\": {\"plant_day\": \"2021-04-30\", \"harvest_day\": \"2021-09-06\"},\n",
    "        \"soybean\": {\"plant_day\": \"2021-04-15\", \"harvest_day\": \"2021-08-16\"},\n",
    "        \"wheat\": {\"plant_day\": \"2021-05-18\", \"harvest_day\": \"2021-09-01\"},\n",
    "        \"sugarbeet\": {\"plant_day\": \"2021-04-28\", \"harvest_day\": \"2021-10-05\"},\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        \"plant_day\": dictAgro[crop][\"plant_day\"].replace(\"2021\", year),\n",
    "        \"harvest_day\": dictAgro[crop][\"harvest_day\"].replace(\"2021\", year),\n",
    "    }\n",
    "\n",
    "\n",
    "def computeCrop(general_df: pd.DataFrame, weather_fname: str, uuid_code: str):\n",
    "    cols = [\"crop\", \"year\", \"WOFOST_FLD\", \"weather_uuid\"]\n",
    "    weather = prepareWeather(weather_fname)\n",
    "    df = pd.DataFrame(columns=cols)\n",
    "\n",
    "    for crop in crops:\n",
    "        for year in range(2015, 2020):\n",
    "            cropCal = getCropCalendar(crop, str(year))\n",
    "            crop_model_yield = run_wofost(\n",
    "                weather=weather,\n",
    "                sowing_date=cropCal[\"plant_day\"],\n",
    "                harvesting_date=cropCal[\"harvest_day\"],\n",
    "                crop_name=crop,\n",
    "                crop_variety=cropsDict[crop],\n",
    "                crop_end_type=\"harvest\",\n",
    "            )\n",
    "            water_limited_df = pd.DataFrame(crop_model_yield[\"FLD\"])\n",
    "            water_limited_yield = crop_model_yield[\"FLD\"][-1][\"TWSO\"]\n",
    "            df.loc[len(df)] = [crop, year, water_limited_yield, uuid_code]\n",
    "    return pd.concat([general_df, df])\n",
    "\n",
    "\n",
    "cropsDict = {\n",
    "    \"barley\": \"Spring_barley_301\",\n",
    "    \"soybean\": \"Soybean_901\",\n",
    "    \"sunflower\": \"Sunflower_1101\",\n",
    "    \"maize\": \"Grain_maize_201\",\n",
    "    \"sugarbeet\": \"Sugarbeet_603\",\n",
    "}\n",
    "\n",
    "\n",
    "cols = [\"crop\", \"year\", \"WOFOST_FLD\"]\n",
    "crops = [\"barley\", \"soybean\", \"sugarbeet\"]\n",
    "\n",
    "\n",
    "def prepare_datasets(dirname: str):\n",
    "    irrad = pd.read_csv(\"predicted_weather/interval_data/irrad.csv\")\n",
    "    tmin = pd.read_csv(\"predicted_weather/interval_data/tmin.csv\")\n",
    "    tmax = pd.read_csv(\"predicted_weather/interval_data/tmax.csv\")\n",
    "    vap = pd.read_csv(\"predicted_weather/interval_data/vap.csv\")\n",
    "    wind = pd.read_csv(\"predicted_weather/interval_data/wind.csv\")\n",
    "    rain = pd.read_csv(\"predicted_weather/interval_data/rain.csv\")\n",
    "    low = pd.read_csv(\"predicted_weather/prophet_low.csv\")\n",
    "\n",
    "\n",
    "def checkIrrad(df: pd.DataFrame)->pd.DataFrame:\n",
    "    df = df.applymap(lambda x: 0 if x<0 else x)\n",
    "    df = df.applymap(lambda x: 40000000-1 if x>40000000 else x)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def checkVAP(df: pd.DataFrame)->pd.DataFrame:\n",
    "    df = df.applymap(lambda x: 0.07 if x<0.06 else x)\n",
    "    df = df.applymap(lambda x: 199.3-1 if x>199.3 else x)\n",
    "    return df\n",
    "\n",
    "def product_columns(n: int, x1: int, x2: int):\n",
    "    logging.info(f\"Compute weathe scenarios: {x1} {x2}\")\n",
    "    cols = [\"crop\", \"year\", \"WOFOST_FLD\", \"weather_uuid\"]\n",
    "    general_df = pd.DataFrame(columns=cols)\n",
    "    dirname = \"predicted_weather\"\n",
    "    logging.info(\"Read weather files\")\n",
    "    irrad = pd.read_csv(os.path.join(dirname, \"interval_data/irrad.csv\"))\n",
    "    irrad  = checkIrrad(irrad)\n",
    "    tmin = pd.read_csv(os.path.join(dirname, \"interval_data/tmin.csv\"))\n",
    "    tmax = pd.read_csv(os.path.join(dirname, \"interval_data/tmax.csv\"))\n",
    "    vap = pd.read_csv(os.path.join(dirname, \"interval_data/vap.csv\"))\n",
    "    vap = checkVAP(vap)\n",
    "    wind = pd.read_csv(os.path.join(dirname, \"interval_data/wind.csv\"))\n",
    "    rain = pd.read_csv(os.path.join(dirname, \"interval_data/rain.csv\"))\n",
    "    low = pd.read_csv(os.path.join(dirname, \"prophet_low.csv\"))\n",
    "    for x3 in range(n + 1):\n",
    "\n",
    "        for x4 in range(n + 1):\n",
    "            for x5 in range(n + 1):\n",
    "                for x6 in range(n + 1):\n",
    "                    tmp = low[[\"DAY\"]].copy()\n",
    "                    tmp[\"IRRAD\"] = irrad[f\"IRRAD_{x1}\"]\n",
    "                    tmp[\"TMIN\"] = tmin[f\"TMIN_{x2}\"]\n",
    "                    tmp[\"TMAX\"] = tmax[f\"TMAX_{x3}\"]\n",
    "                    tmp[\"VAP\"] = vap[f\"VAP_{x4}\"]\n",
    "                    tmp[\"WIND\"] = wind[f\"WIND_{x5}\"]\n",
    "                    tmp[\"RAIN\"] = rain[f\"RAIN_{x6}\"]\n",
    "                    tmp[\"SNOWDEPTH\"] = low[[\"SNOWDEPTH\"]]\n",
    "                    fname = os.path.join(dirname, f\"interval_data/{x1}_{x2}_{x3}_{x4}_{x5}_{x6}.csv\")\n",
    "\n",
    "                    weather_uuid = f\"{x1}_{x2}_{x3}_{x4}_{x5}_{x6}\"\n",
    "                    tmp.to_csv(fname, index=False)\n",
    "        \n",
    "                    general_df = computeCrop(\n",
    "                        general_df=general_df,\n",
    "                        weather_fname=fname,\n",
    "                        uuid_code=weather_uuid,\n",
    "                    )\n",
    "                    os.remove(fname)\n",
    "                    # save data\n",
    "                    if len(general_df) % 1000 == 0:\n",
    "                        dirname = \"./results/\"\n",
    "                        general_fname = os.path.join(dirname, f\"WOFOST_{x1}_{x2}.csv\")\n",
    "                        general_df.to_csv(general_fname, index=False)\n",
    "\n",
    "    return general_df\n",
    "\n",
    "\n",
    "\n",
    "def main(x1: int, x2: int):\n",
    "    all_files = product_columns(n=8, x1=0, x2=1)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "\n",
    "    logging.basicConfig(\n",
    "        format=\"- %(asctime)s - %(levelname)s - %(message)s\",\n",
    "        level=logging.INFO,\n",
    "        datefmt=\"%H:%M:%S\",\n",
    "    )\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument(\"--x1\", default=0, type=int)\n",
    "    parser.add_argument(\"--x2\", default=0, type=int)\n",
    "    args = parser.parse_args()\n",
    "    main(x1=args.x1, x2=args.x2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function connect.<locals>.remove at 0x13e1b9790>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mikhailgasanov/geo/lib/python3.8/site-packages/pcse/pydispatch/dispatcher.py\", line 144, in remove\n",
      "    def remove(object, senderkey=senderkey):\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "main(x1=0, x2=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IRRAD_0</th>\n",
       "      <th>IRRAD_1</th>\n",
       "      <th>IRRAD_2</th>\n",
       "      <th>IRRAD_3</th>\n",
       "      <th>IRRAD_4</th>\n",
       "      <th>IRRAD_5</th>\n",
       "      <th>IRRAD_6</th>\n",
       "      <th>IRRAD_7</th>\n",
       "      <th>IRRAD_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1345.180534</td>\n",
       "      <td>2808.997561</td>\n",
       "      <td>4272.814589</td>\n",
       "      <td>5736.631616</td>\n",
       "      <td>7200.448644</td>\n",
       "      <td>8664.265671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1219.350127</td>\n",
       "      <td>2600.870634</td>\n",
       "      <td>3982.391141</td>\n",
       "      <td>5363.911648</td>\n",
       "      <td>6745.432155</td>\n",
       "      <td>8126.952662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1286.667397</td>\n",
       "      <td>2641.293990</td>\n",
       "      <td>3995.920583</td>\n",
       "      <td>5350.547176</td>\n",
       "      <td>6705.173769</td>\n",
       "      <td>8059.800362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1262.185892</td>\n",
       "      <td>2690.576839</td>\n",
       "      <td>4118.967786</td>\n",
       "      <td>5547.358734</td>\n",
       "      <td>6975.749681</td>\n",
       "      <td>8404.140628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1276.231420</td>\n",
       "      <td>2666.667893</td>\n",
       "      <td>4057.104366</td>\n",
       "      <td>5447.540839</td>\n",
       "      <td>6837.977311</td>\n",
       "      <td>8228.413784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1821</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>879.350765</td>\n",
       "      <td>2355.330836</td>\n",
       "      <td>3831.310907</td>\n",
       "      <td>5307.290978</td>\n",
       "      <td>6783.271050</td>\n",
       "      <td>8259.251121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>829.867757</td>\n",
       "      <td>2292.550481</td>\n",
       "      <td>3755.233204</td>\n",
       "      <td>5217.915928</td>\n",
       "      <td>6680.598652</td>\n",
       "      <td>8143.281376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>595.133688</td>\n",
       "      <td>2065.109866</td>\n",
       "      <td>3535.086043</td>\n",
       "      <td>5005.062221</td>\n",
       "      <td>6475.038398</td>\n",
       "      <td>7945.014576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1824</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>886.378722</td>\n",
       "      <td>2351.992801</td>\n",
       "      <td>3817.606880</td>\n",
       "      <td>5283.220960</td>\n",
       "      <td>6748.835039</td>\n",
       "      <td>8214.449118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>960.697998</td>\n",
       "      <td>2410.545885</td>\n",
       "      <td>3860.393772</td>\n",
       "      <td>5310.241659</td>\n",
       "      <td>6760.089546</td>\n",
       "      <td>8209.937434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1826 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      IRRAD_0  IRRAD_1  IRRAD_2      IRRAD_3      IRRAD_4      IRRAD_5  \\\n",
       "0         0.0      0.0      0.0  1345.180534  2808.997561  4272.814589   \n",
       "1         0.0      0.0      0.0  1219.350127  2600.870634  3982.391141   \n",
       "2         0.0      0.0      0.0  1286.667397  2641.293990  3995.920583   \n",
       "3         0.0      0.0      0.0  1262.185892  2690.576839  4118.967786   \n",
       "4         0.0      0.0      0.0  1276.231420  2666.667893  4057.104366   \n",
       "...       ...      ...      ...          ...          ...          ...   \n",
       "1821      0.0      0.0      0.0   879.350765  2355.330836  3831.310907   \n",
       "1822      0.0      0.0      0.0   829.867757  2292.550481  3755.233204   \n",
       "1823      0.0      0.0      0.0   595.133688  2065.109866  3535.086043   \n",
       "1824      0.0      0.0      0.0   886.378722  2351.992801  3817.606880   \n",
       "1825      0.0      0.0      0.0   960.697998  2410.545885  3860.393772   \n",
       "\n",
       "          IRRAD_6      IRRAD_7      IRRAD_8  \n",
       "0     5736.631616  7200.448644  8664.265671  \n",
       "1     5363.911648  6745.432155  8126.952662  \n",
       "2     5350.547176  6705.173769  8059.800362  \n",
       "3     5547.358734  6975.749681  8404.140628  \n",
       "4     5447.540839  6837.977311  8228.413784  \n",
       "...           ...          ...          ...  \n",
       "1821  5307.290978  6783.271050  8259.251121  \n",
       "1822  5217.915928  6680.598652  8143.281376  \n",
       "1823  5005.062221  6475.038398  7945.014576  \n",
       "1824  5283.220960  6748.835039  8214.449118  \n",
       "1825  5310.241659  6760.089546  8209.937434  \n",
       "\n",
       "[1826 rows x 9 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.applymap(lambda x: 0 if x<0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index([('I', 'R', 'R', 'A', 'D', '_', '0'),\\n       ('I', 'R', 'R', 'A', 'D', '_', '1'),\\n       ('I', 'R', 'R', 'A', 'D', '_', '2'),\\n       ('I', 'R', 'R', 'A', 'D', '_', '3'),\\n       ('I', 'R', 'R', 'A', 'D', '_', '4'),\\n       ('I', 'R', 'R', 'A', 'D', '_', '5'),\\n       ('I', 'R', 'R', 'A', 'D', '_', '6'),\\n       ('I', 'R', 'R', 'A', 'D', '_', '7'),\\n       ('I', 'R', 'R', 'A', 'D', '_', '8')],\\n      dtype='object')] are in the [index]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/1f/xyznj37x1n337kxt0v5533rw0000gn/T/ipykernel_13481/1763106016.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# def checkIrrad(df: pd.DataFrame)->pd.DataFrame:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m40000000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m40000000\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/geo/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    717\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_valid_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/geo/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_setitem_indexer\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_setter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    667\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/geo/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, key, axis, is_setter)\u001b[0m\n\u001b[1;32m   1255\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0minds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1257\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1258\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/geo/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1312\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m         if needs_i8_conversion(ax.dtype) or isinstance(\n",
      "\u001b[0;32m~/geo/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis)\u001b[0m\n\u001b[1;32m   1372\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muse_interval_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m                     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index([('I', 'R', 'R', 'A', 'D', '_', '0'),\\n       ('I', 'R', 'R', 'A', 'D', '_', '1'),\\n       ('I', 'R', 'R', 'A', 'D', '_', '2'),\\n       ('I', 'R', 'R', 'A', 'D', '_', '3'),\\n       ('I', 'R', 'R', 'A', 'D', '_', '4'),\\n       ('I', 'R', 'R', 'A', 'D', '_', '5'),\\n       ('I', 'R', 'R', 'A', 'D', '_', '6'),\\n       ('I', 'R', 'R', 'A', 'D', '_', '7'),\\n       ('I', 'R', 'R', 'A', 'D', '_', '8')],\\n      dtype='object')] are in the [index]\""
     ]
    }
   ],
   "source": [
    "dirname = \"predicted_weather\"\n",
    "    \n",
    "df = pd.read_csv(os.path.join(dirname, \"interval_data/irrad.csv\"))\n",
    "# irrad  = checkIrrad(irrad)\n",
    "\n",
    "# def checkIrrad(df: pd.DataFrame)->pd.DataFrame:\n",
    "mask = df<0\n",
    "df.loc[mask] = 0 \n",
    "mask = df>40000000\n",
    "df.loc[mask] = 40000000-1\n",
    "    # return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(weather.export())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 ('geo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2624297a14b2e5b247b0fc8a92b75a581cd32613a3f7f56c6b107af7b0801f07"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
